{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch_geometric.data import Dataset, InMemoryDataset, download_url, Data\n",
    "from torch_geometric.transforms import BaseTransform, Compose\n",
    "from torch_geometric.utils import remove_self_loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale(BaseTransform):\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        \n",
    "        for key in data.keys():\n",
    "            \n",
    "            if key != 'y':\n",
    "                offset = (data[key] - torch.min(data[key]))\n",
    "                max =  torch.max(data[key] - torch.min(data[key]))\n",
    "                scaled_attr = offset / max \n",
    "                data[key] = scaled_attr\n",
    "        \n",
    "        return data\n",
    "\n",
    "#scale_transform = Scale()\n",
    "\n",
    "#data_new = scale_transform(data)\n",
    "\n",
    "#torch.max(data_new.u_dm), torch.min(data_new.u_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CompleteGraph(BaseTransform):\n",
    "    \"\"\"\n",
    "    This transform adds all pairwise edges into the edge index per data sample,\n",
    "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        \n",
    "        #device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long)#, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long)#, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenateGlobal(BaseTransform):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        BaseTransform (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        u = torch.concatenate([torch.flatten(data.u_chem), torch.flatten(data.u_dm)])\n",
    "        del data.u_dm\n",
    "        del data.u_chem\n",
    "        data.u = u\n",
    "        \n",
    "        return data\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import logging\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import datamol as dm\n",
    "from graphium.features import featurizer as gff\n",
    "#logging.basicConfig\n",
    "\n",
    "class Dataset(InMemoryDataset):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        InMemoryDataset (_type_): _description_\n",
    "    \"\"\"\n",
    "    def __init__(self, path_data: str, type_data: str, \n",
    "                 pre_transform: callable = Compose([Scale(), CompleteGraph(), ConcatenateGlobal()]), \n",
    "                 transform = None,pre_filter=None, **kwargs):\n",
    "        #self.size = size\n",
    "        self.type_data = type_data\n",
    "        self.path_data= path_data\n",
    "        super().__init__(pre_transform=pre_transform, transform=transform, pre_filter=None, **kwargs)\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self) -> list[str]:\n",
    "        raw_files = os.listdir(self.path_data + \"/\" + self.type_data + \"/raw\" )\n",
    "        return raw_files\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self) -> list[str]:\n",
    "        #raw_files = os.listdir(self.path_data + '/' + self.type_data + '/raw' )\n",
    "        raw_files = self.raw_file_names\n",
    "        total_rows = 0\n",
    "        \n",
    "        for file in raw_files: \n",
    "            df_data = pd.read_csv(self.path_data + \"/\" + self.type_data + \"/raw/\" +  file)\n",
    "            total_rows =+ len(df_data)\n",
    "        \n",
    "        return  [f'data_{row}' for row in range(total_rows)]\n",
    "\n",
    "    def process(self) -> None:\n",
    "        #raw_files = os.listdir(self.path_data + '/' + self.type_data + '/raw' )\n",
    "        raw_files = self.raw_file_names\n",
    "        pipe = pipeline(\"feature-extraction\", model=\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "        \n",
    "        for file in raw_files:\n",
    "            df_data = pd.read_csv(self.path_data + \"/\" + self.type_data + \"/raw/\" +  file)\n",
    "            \n",
    "\n",
    "            for rows in range(1):#(len(df_data)):\n",
    "                dm.disable_rdkit_log() # stop logging a lot of info for datamol methods calls\n",
    "                \n",
    "                smile = df_data['CXSMILES'][rows]\n",
    "                mol = dm.to_mol(smile, add_hs=True)\n",
    "                mol = dm.sanitize_mol(mol)\n",
    "                mol = dm.fix_mol(mol)\n",
    "                mol = dm.standardize_mol(\n",
    "                                        mol,\n",
    "                                        disconnect_metals=True,\n",
    "                                        normalize=True,\n",
    "                                        reionize=True,\n",
    "                                        uncharge=False,\n",
    "                                        stereo=True,\n",
    "                                        )\n",
    "                                \n",
    "                u1 = pipe(df_data['CXSMILES'][rows])\n",
    "                u_chem = torch.tensor(u1[0][0], dtype=torch.float)\n",
    "                \n",
    "                \n",
    "                descriptors = dm.descriptors.compute_many_descriptors(mol)\n",
    "                u2 = list(descriptors.values())\n",
    "                u_dm = torch.tensor(u2, dtype=torch.float)\n",
    "                \n",
    "                atomic_features = [ \"atomic-number\", \"mass\", \"weight\",\"valence\",\"total-valence\",\n",
    "                                    \"implicit-valence\",\"hybridization\",\"ring\", \"in-ring\",\"min-ring\",\n",
    "                                    \"max-ring\",\"num-ring\",\"degree\",\"radical-electron\",\"formal-charge\",\n",
    "                                    \"vdw-radius\",\"covalent-radius\",\"electronegativity\",\"ionization\",\n",
    "                                    \"first-ionization\",\"melting-point\",\"metal\",\"single-bond\",\"aromatic-bond\",\n",
    "                                    \"double-bond\",\"triple-bond\",\"is-carbon\",\"group\",\"period\" ]\n",
    "                \n",
    "                edge_features = [\"bond-type-float\", \"in-ring\", \"conjugated\", \"estimated-bond-length\"]\n",
    "                \n",
    "                data = gff.mol_to_pyggraph(mol, atom_property_list_float=atomic_features, edge_property_list=edge_features)\n",
    "                return data\n",
    "                #values_atomic_feat = gff.get_mol_atomic_features_float(mol, atomic_features, mask_nan='warn').values()\n",
    "                x_array = np.column_stack(list(values_atomic_feat))\n",
    "                #x = torch.tensor(x_array, dtype=torch.float)\n",
    "                \n",
    "                #refine selection of arguments for dm.confomers.generate()\n",
    "                n_confs = 8\n",
    "                #mol_confs = dm.conformers.generate(mol, n_confs=n_confs)\n",
    "                list_xyz = [mol_confs.GetConformer(i).GetPositions() for i in range(n_confs)]\n",
    "                pos_array = np.stack(list_xyz, axis=1)\n",
    "                pos = torch.tensor(pos_array, dtype=torch.float)\n",
    "                \n",
    "                edge_features = [\"bond-type-float\", \"in-ring\", \"conjugated\", \"estimated-bond-length\"]\n",
    "                # additional edge features:\"bond-type-onehot\", \"stereo\",conformer-bond-length\" (might cause problems with complex molecules)\n",
    "                edge_dict = gff.get_mol_edge_features(mol, edge_features, mask_nan='warn')          \n",
    "                edge_list = list(edge_dict.values())\n",
    "                edge = np.column_stack(edge_list)\n",
    "                edge_feat = torch.tensor(edge, dtype=torch.float)\n",
    "                \n",
    "                df_y = df_data[[\"pIC50 (MERS-CoV Mpro)\", \"pIC50 (SARS-CoV-2 Mpro)\"]]\n",
    "                y = torch.tensor(np.array(df_y), dtype=torch.float)\n",
    "                \n",
    "                data = Data(u_chem=u_chem, u_dm=u_dm, edge_feat=edge_feat, pos=pos, x=x, y=y)\n",
    "                \n",
    "                \n",
    "                \"\"\" # Scale (all), Concatenate(only global features u) and complete graph\n",
    "                if self.pre_transform is not None:\n",
    "                    data = self.pre_transform(data)\n",
    "                \n",
    "                #Save the processed data\n",
    "                path_processed = self.path_data + \"/\" + self.type_data + \"/\" + \"processed\" \n",
    "                \n",
    "                if os.path.isdir(path_processed) != False:\n",
    "                    os.mkdir(path_processed)\n",
    "                \n",
    "                torch.save(data, os.path.join(path_processed, f\"data_{rows}.pt\"))\n",
    "                 \"\"\"\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = Dataset('/home/slav/Documents/github/repo/DSR_Project/polaris-ligand-potency/data', 'train' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Device set to use cuda:0\n",
      "Done!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DataLoader found invalid type: '<class 'NoneType'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/slav/Documents/github/repo/DSR_Project/polaris-ligand-potency/data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
      "File \u001b[0;32m~/anaconda3/envs/DSRProject/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/DSRProject/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/DSRProject/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/DSRProject/lib/python3.12/site-packages/torch_geometric/loader/dataloader.py:49\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)]\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader found invalid type: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(elem)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: DataLoader found invalid type: '<class 'NoneType'>'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "train_dataset = Dataset('/home/slav/Documents/github/repo/DSR_Project/polaris-ligand-potency/data', 'train')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor(6.) u_dm: tensor(299.1270) pos: tensor(4.2711) u_chem: tensor(3.9375)\n"
     ]
    }
   ],
   "source": [
    "print( 'x:', torch.max(data.x), 'u_dm:', torch.max(data.u_dm),  'pos:', torch.max(data.pos), 'u_chem:', torch.max(data.u_chem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['x', 'edge_feat', 'edge_index', 'y', 'pos', 'u'],\n",
       " ['x', 'edge_feat', 'u_dm', 'y', 'pos', 'u_chem'])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = Compose([Scale(), ConcatenateGlobal(), CompleteGraph()])\n",
    "\n",
    "data_new = transform(data)\n",
    "\n",
    "data_new.keys(), data.keys()\n",
    "#torch.max(data_new.u_dm), torch.min(data_new.u_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(\"./DSRProject/polaris-ligand-potency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSRProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
