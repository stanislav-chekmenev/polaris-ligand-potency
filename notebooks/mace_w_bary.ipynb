{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "\n",
    "from models import MACEBaryModel\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mace_kwargs = {\n",
    "    \"r_max\": 5,\n",
    "    \"num_bessel\": 10,\n",
    "    \"num_polynomial_cutoff\": 6,\n",
    "    \"max_ell\": 2,\n",
    "    \"correlation\": 3,\n",
    "    \"num_layers\": 5,\n",
    "    \"emb_dim\": 64,\n",
    "    \"hidden_irreps\": None,\n",
    "    \"mlp_dim\": 256,\n",
    "    \"in_dim\": cfg.NUM_POSSIBLE_ATOMS,\n",
    "    \"out_dim\": 1,\n",
    "    \"aggr\": \"sum\",\n",
    "    \"pool\": \"sum\",\n",
    "    \"batch_norm\": True,\n",
    "    \"residual\": True,\n",
    "    \"equivariant_pred\": True,\n",
    "    \"as_featurizer\": True,\n",
    "}\n",
    "\n",
    "mace_bary = MACEBaryModel(mace_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import datamol as dm\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import torch\n",
    "\n",
    "from graphium.features import featurizer as gff\n",
    "from datamol.descriptors.compute import _DEFAULT_PROPERTIES_FN\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import BaseTransform, Compose, NormalizeScale\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CompleteGraph(BaseTransform):\n",
    "    \"\"\"\n",
    "    This transform adds all pairwise edges into the edge index per data sample,\n",
    "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        \n",
    "        device = data.edge_index.device\n",
    "\n",
    "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
    "\n",
    "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
    "        col = col.repeat(data.num_nodes)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "        edge_attr = None\n",
    "        if data.edge_attr is not None:\n",
    "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
    "            size = list(data.edge_attr.size())\n",
    "            size[0] = data.num_nodes * data.num_nodes\n",
    "            edge_attr = data.edge_attr.new_zeros(size)\n",
    "            edge_attr[idx] = data.edge_attr\n",
    "\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "        data.edge_attr = edge_attr\n",
    "        data.edge_index = edge_index\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenateGlobal(BaseTransform):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        BaseTransform (_type_): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        u = torch.concatenate([data.u_chem, data.u_dm], dim=0).view(1, -1)\n",
    "        del data.u_dm\n",
    "        del data.u_chem\n",
    "        data.u = u\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the number of processed SMILES to the length of the dataframe\n",
    "# for idx in tqdm(range(10), desc=\"Processing molecules\", total=len(df_data)): -> for idx in tqdm(range(lrn(df_data)), desc=\"Processing molecules\", total=len(df_data)):\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MolDataset(InMemoryDataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            root: str, \n",
    "            pre_transform: callable = Compose([NormalizeScale(), ConcatenateGlobal()]), \n",
    "            transform = None, \n",
    "            **kwargs\n",
    "        ):\n",
    "        super().__init__(root, pre_transform=pre_transform, transform=transform, **kwargs)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> list[str]:\n",
    "        raw_files = os.listdir(self.raw_dir)\n",
    "        return raw_files\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self) -> list[str]:\n",
    "        raw_files = os.listdir(self.raw_dir)\n",
    "        processed_files = [raw_file.replace(\".csv\", \".pt\") for raw_file in raw_files]\n",
    "        return processed_files\n",
    "    \n",
    "    def normalize_mol_descriptors(self, data_list, desc_mins, desc_maxs):\n",
    "        # Normalize the molecular descriptors to the range [0, 1]\n",
    "        for data in data_list:\n",
    "            data.u_dm = (data.u_dm - desc_mins) / (desc_maxs - desc_mins)\n",
    "            data.u_dm = torch.nan_to_num(data.u_dm, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    def process(self) -> None:\n",
    "        raw_files = self.raw_file_names\n",
    "        \n",
    "        # Get ChemBERTa model\n",
    "        pipe = pipeline(\"feature-extraction\", model=\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "        \n",
    "        # Read the raw data\n",
    "        df_data = pd.read_csv(os.path.join(self.raw_dir, raw_files[0]), header=0)\n",
    "\n",
    "        # Create a list to store the data objects\n",
    "        data_list = []\n",
    "\n",
    "        # Init an array to hold the statistics of the molecular descriptors\n",
    "        desc_mins = torch.ones(len(_DEFAULT_PROPERTIES_FN), dtype=torch.float) * 10_000\n",
    "        desc_maxs = -torch.ones(len(_DEFAULT_PROPERTIES_FN), dtype=torch.float) * 10_000\n",
    "\n",
    "        for idx in tqdm(range(10), desc=\"Processing molecules\", total=len(df_data)):\n",
    "            dm.disable_rdkit_log() # stop logging a lot of info for datamol methods calls\n",
    "            \n",
    "            smile = df_data['CXSMILES'][idx]\n",
    "            mol = dm.to_mol(smile, add_hs=True)\n",
    "            mol = dm.sanitize_mol(mol)\n",
    "            mol = dm.fix_mol(mol)\n",
    "            mol = dm.standardize_mol(\n",
    "                mol,\n",
    "                disconnect_metals=True,\n",
    "                normalize=True,\n",
    "                reionize=True,\n",
    "                uncharge=False,\n",
    "                stereo=True,\n",
    "            )\n",
    "\n",
    "            # Get CHEMBERTa features              \n",
    "            u = pipe(df_data['CXSMILES'].iloc[idx])\n",
    "            u_chem = torch.tensor(u[0][0], dtype=torch.float)\n",
    "            \n",
    "            # Get Datamol molecular features\n",
    "            descriptors = dm.descriptors.compute_many_descriptors(mol)\n",
    "            u = list(descriptors.values())\n",
    "            u_dm = torch.tensor(u, dtype=torch.float)\n",
    "\n",
    "            # Update the statistics of the molecular descriptors\n",
    "            desc_maxs= torch.where(u_dm > desc_maxs, u_dm, desc_maxs)\n",
    "            desc_mins = torch.where(u_dm < desc_mins, u_dm, desc_mins)\n",
    "            \n",
    "            # Allowable atomic node and edge features\n",
    "            atomic_features = [ \"atomic-number\", \"mass\", \"weight\",\"valence\",\"total-valence\",\n",
    "                                \"implicit-valence\",\"hybridization\",\"ring\", \"in-ring\",\"min-ring\",\n",
    "                                \"max-ring\",\"num-ring\",\"degree\",\"radical-electron\",\"formal-charge\",\n",
    "                                \"vdw-radius\",\"covalent-radius\",\"electronegativity\",\"ionization\",\n",
    "                                \"first-ionization\",\"metal\",\"single-bond\",\"aromatic-bond\",\n",
    "                                \"double-bond\",\"triple-bond\",\"is-carbon\",\"group\",\"period\" ]\n",
    "            \n",
    "            edge_features = [\"bond-type-onehot\", \"in-ring\", \"conjugated\", \"estimated-bond-length\"]\n",
    "            \n",
    "            # Get float atomic features\n",
    "            values_atomic_feat = gff.get_mol_atomic_features_float(mol, atomic_features, mask_nan='warn').values()\n",
    "            x_array = np.column_stack(list(values_atomic_feat))\n",
    "            x = torch.tensor(x_array, dtype=torch.float)\n",
    "            \n",
    "            # Get one-hot atomic numbers\n",
    "            atoms_onehot = gff.get_mol_atomic_features_onehot(mol, [\"atomic-number\"]).values()\n",
    "            atoms_onehot = np.column_stack(list(atoms_onehot))\n",
    "            atoms_onehot = torch.tensor(atoms_onehot, dtype=torch.float)\n",
    "            # Transform onehot to indices of possible atoms\n",
    "            atoms = torch.where(atoms_onehot > 0)[1]\n",
    "\n",
    "            # Generate conformers\n",
    "            try:\n",
    "                mol_confs = dm.conformers.generate(mol, n_confs=cfg.NUM_CONFORMERS)\n",
    "                list_xyz = [mol_confs.GetConformer(i).GetPositions() for i in range(cfg.NUM_CONFORMERS)]\n",
    "                pos_array = np.stack(list_xyz, axis=1)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Conformer generation failed for {smile}: {e}\")\n",
    "                logger.info(\"Setting atom positions to all zeros\")\n",
    "                pos_array = np.zeros((x.shape[0], cfg.NUM_CONFORMERS, 3))\n",
    "            pos = torch.tensor(pos_array, dtype=torch.float)\n",
    "            \n",
    "            # Additional edge features:\"bond-type-onehot\", \"stereo\",conformer-bond-length\" (might cause problems with complex molecules)\n",
    "            edge_dict = gff.get_mol_edge_features(mol, edge_features, mask_nan='warn')          \n",
    "            edge_list = list(edge_dict.values())\n",
    "            edge_attr = np.column_stack(edge_list)\n",
    "            edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "            \n",
    "            # Repeat edge_attr twice to account for both directions of the edges\n",
    "            edge_attr = edge_attr.repeat_interleave(2, dim=0)\n",
    "\n",
    "            # Get adjacency matrix\n",
    "            adj = gff.mol_to_adjacency_matrix(mol)\n",
    "            edge_index = torch.stack([torch.tensor(adj.coords[0], dtype=torch.int64), torch.tensor(adj.coords[1], dtype=torch.int64)], dim=0)\n",
    "\n",
    "            # Get the target values\n",
    "            df_y = df_data[[\"pIC50 (MERS-CoV Mpro)\", \"pIC50 (SARS-CoV-2 Mpro)\"]].iloc[idx]\n",
    "            y = torch.tensor(np.array(df_y), dtype=torch.float)\n",
    "            \n",
    "            # Get a PyG data object\n",
    "            data = Data(u_chem=u_chem, u_dm=u_dm, edge_attr=edge_attr, pos=pos, x=x, y=y, atoms=atoms, edge_index=edge_index)\n",
    "            \n",
    "            # Append the data object to the list\n",
    "            data_list.append(data)\n",
    "        \n",
    "\n",
    "        # Normalize molecular descriptors\n",
    "        self.normalize_mol_descriptors(data_list, desc_mins, desc_maxs)\n",
    "\n",
    "        # Apply the pre_transform if provided\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "\n",
    "        #Save the processed data\n",
    "        self.save(data_list, self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MolDataset(root=cfg.TRAIN_DIR)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=cfg.NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[23, 24], edge_index=[2, 52], edge_attr=[52, 8], y=[2], pos=[23, 10, 3], atoms=[23], u=[1, 790], batch=[23], ptr=[2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batch.to(cfg.DEVICE)\n",
    "batch.x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(mace_bary.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mace_bary = mace_bary.to(cfg.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = mace_bary(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69, 576])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[23, 24], edge_index=[2, 52], edge_attr=[52, 8], y=[2], pos=[23, 3, 3], atoms=[23], u=[1, 790])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.csgraph import shortest_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34957/3985442759.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  debug_dict = torch.load('cfm_log.pt')\n"
     ]
    }
   ],
   "source": [
    "debug_dict = torch.load('cfm_log.pt')\n",
    "N = debug_dict[\"N\"]\n",
    "Ys = debug_dict[\"Ys\"]\n",
    "Cs = debug_dict[\"Cs\"]\n",
    "ps = debug_dict[\"ps\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(torch.all(Cs[0] == Cs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polaris-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
